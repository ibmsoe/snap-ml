{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HIGGS example using IBM PowerAI Snap ML\n",
    "\n",
    "In this example we will train a Logistic Regression model on the HIGGS dataset, using both scikit-learn and snap-ml-local.\n",
    "\n",
    "The HIGGS dataset is avaliable in the UCI machine learning repository.\n",
    "\n",
    "To avoid 'kernel restart' problem increase CPU and memory for the jupyter environment (e.g. memory 10GB, CPU 100) and restart it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download input data\n",
    "\n",
    "Two wget commands are given below for downloading input HIGGS dataset - one for reduced dataset and another for bigger/full dataset. Many times better perfomance of snapML training is seen with bigger dataset.\n",
    "\n",
    "You can comment the line containing the wget command to avoid downloading dataset again if running the same wget command more than once. Similarly preprocessing code can be commented out second time onwards if using the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘HIGGS.bz2’ already there; not retrieving.\r\n",
      "\r\n",
      "bunzip2: Output file HIGGS already exists.\r\n"
     ]
    }
   ],
   "source": [
    "# About 3 times better training time with snapML compared to sklearn with this full HIGGS dataset\n",
    "!mkdir -p data; cd data; wget -nc https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/HIGGS.bz2; bunzip2 HIGGS.bz2; cd ../\n",
    "\n",
    "# Download reduced dataset\n",
    "#!mkdir -p data; cd data; wget -O HIGGS -nc https://ibm.box.com/shared/static/v684mqemrrz9o9gsko4ox5l30t6ncqag; cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "defaultPath = \".\"\n",
    "\n",
    "X,y = load_svmlight_file(defaultPath + \"/data/HIGGS\")\n",
    "\n",
    "# Make the train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert to numpy ararys\n",
    "import numpy as np\n",
    "X_train = np.array(X_train.todense())\n",
    "X_test  = np.array(X_test.todense())\n",
    "\n",
    "# Normalize the training data\n",
    "from sklearn.preprocessing import normalize\n",
    "X_train = normalize(X_train, axis=1, norm='l1')\n",
    "X_test  = normalize(X_test,  axis=1, norm='l1')\n",
    "\n",
    "# Save the dense matrices\n",
    "np.save(defaultPath + \"/data/HIGGS.X_train\", X_train)\n",
    "np.save(defaultPath + \"/data/HIGGS.X_test\",  X_test)\n",
    "\n",
    "# Save the labels\n",
    "np.save(defaultPath + \"/data/HIGGS.y_train\", y_train)\n",
    "np.save(defaultPath + \"/data/HIGGS.y_test\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating a Logistic Regression Model using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data load time (s):  0.26\n",
      "[Warning] Parameter device_ids not set. The training will run on GPU 0.\n",
      "[snap.ml] Training time (s):  2.47\n",
      "[snap.ml] Logarithmic loss:   0.6374\n",
      "[sklearn] Training time (s):  74.43\n",
      "[sklearn] Logarithmic loss:   0.6374\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluating a Logistic Regression Model using GPU\n",
    "from scipy import sparse\n",
    "\n",
    "# Load the data\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "defaultPath = \".\"\n",
    "\n",
    "t0 = time.time()\n",
    "X_train = np.load(defaultPath + \"/data/HIGGS.X_train.npy\")\n",
    "X_test  = np.load(defaultPath + \"/data/HIGGS.X_test.npy\")\n",
    "y_train = np.load(defaultPath + \"/data/HIGGS.y_train.npy\")\n",
    "y_test  = np.load(defaultPath + \"/data/HIGGS.y_test.npy\")\n",
    "print(\"Data load time (s):  {0:.2f}\".format(time.time()-t0))\n",
    "\n",
    "# Import the LogisticRegression from snap.ml\n",
    "from snap_ml import LogisticRegression\n",
    "lr = LogisticRegression(use_gpu=True, max_iter=15, dual=True, num_threads=32, device_ids=[])\n",
    "\n",
    "# Training\n",
    "t0 = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"[snap.ml] Training time (s):  {0:.2f}\".format(time.time()-t0))\n",
    "\n",
    "# Inference\n",
    "proba_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Evaluate log-loss on test set\n",
    "from sklearn.metrics import log_loss\n",
    "logloss_snap = log_loss(y_test, proba_test)\n",
    "print(\"[snap.ml] Logarithmic loss:   {0:.4f}\".format(logloss_snap))\n",
    "\n",
    "# Import the LogisticRegression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(fit_intercept=False, dual=True)\n",
    "\n",
    "# Training time\n",
    "t0 = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"[sklearn] Training time (s):  {0:.2f}\".format(time.time()-t0))\n",
    "\n",
    "# Inference\n",
    "proba_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Evaluate log-loss on test set\n",
    "logloss_sklearn = log_loss(y_test, proba_test)\n",
    "print(\"[sklearn] Logarithmic loss:   {0:.4f}\".format(logloss_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating a Logistic Regression Model using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data load time (s):  0.19\n",
      "[Info][Experimental feature] Training will run in multi-threaded mode on CPU. Training convergence is not guaranteed.\n",
      "[snap.ml] Training time (s):  23.47\n",
      "[snap.ml] Logarithmic loss:   0.6379\n",
      "[sklearn] Training time (s):  69.51\n",
      "[sklearn] Logarithmic loss:   0.6374\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluating a Logistic Regression Model using CPU\n",
    "from scipy import sparse\n",
    "\n",
    "# Load the data\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "defaultPath = \".\"\n",
    "\n",
    "t0 = time.time()\n",
    "X_train = np.load(defaultPath + \"/data/HIGGS.X_train.npy\")\n",
    "X_test  = np.load(defaultPath + \"/data/HIGGS.X_test.npy\")\n",
    "y_train = np.load(defaultPath + \"/data/HIGGS.y_train.npy\")\n",
    "y_test  = np.load(defaultPath + \"/data/HIGGS.y_test.npy\")\n",
    "print(\"Data load time (s):  {0:.2f}\".format(time.time()-t0))\n",
    "\n",
    "# Import the LogisticRegression from snap.ml\n",
    "from snap_ml import LogisticRegression\n",
    "lr = LogisticRegression(use_gpu=False, max_iter=15, dual=True, num_threads=32, device_ids=[])\n",
    "\n",
    "# Training\n",
    "t0 = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"[snap.ml] Training time (s):  {0:.2f}\".format(time.time()-t0))\n",
    "\n",
    "# Inference\n",
    "proba_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Evaluate log-loss on test set\n",
    "from sklearn.metrics import log_loss\n",
    "logloss_snap = log_loss(y_test, proba_test)\n",
    "print(\"[snap.ml] Logarithmic loss:   {0:.4f}\".format(logloss_snap))\n",
    "\n",
    "# Import the LogisticRegression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(fit_intercept=False, dual=True)\n",
    "\n",
    "# Training time\n",
    "t0 = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"[sklearn] Training time (s):  {0:.2f}\".format(time.time()-t0))\n",
    "\n",
    "# Inference\n",
    "proba_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Evaluate log-loss on test set\n",
    "logloss_sklearn = log_loss(y_test, proba_test)\n",
    "print(\"[sklearn] Logarithmic loss:   {0:.4f}\".format(logloss_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy; Copyright IBM Corporation 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
